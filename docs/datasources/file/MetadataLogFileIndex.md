# MetadataLogFileIndex

`MetadataLogFileIndex` is a `PartitioningAwareFileIndex` of [metadata log files](#allFilesFromLog) (generated by [FileStreamSink](FileStreamSink.md)).

!!! tip
    Learn more about [PartitioningAwareFileIndex]({{ book.spark_sql }}/PartitioningAwareFileIndex) in [The Internals of Spark SQL]({{ book.spark_sql }}) online book.

## Creating Instance

`MetadataLogFileIndex` takes the following to be created:

* <span id="sparkSession"> `SparkSession`
* <span id="path"> Hadoop [Path]({{ hadoop.api }}/org/apache/hadoop/fs/Path.html)
* <span id="parameters"> Parameters (`Map[String, String]`)
* <span id="userSpecifiedSchema"> User-Defined Schema (`Option[StructType]`)

`MetadataLogFileIndex` is created when:

* `DataSource` is requested to [resolveRelation](../../DataSource.md#resolveRelation) (for `FileFormat` streaming data sources)
* `FileTable` is requested for a `PartitioningAwareFileIndex` (for `FileFormat` streaming data sources)
* `FileStreamSource` is requested to [allFilesUsingMetadataLogFileIndex](FileStreamSource.md#allFilesUsingMetadataLogFileIndex)

While being created, `MetadataLogFileIndex` prints out the following INFO message to the logs (with the [metadataDirectory](#metadataDirectory)):

```text
Reading streaming file log from [metadataDirectory]
```

## <span id="metadataDirectory"> Metadata Directory

```scala
metadataDirectory: Path
```

`metadataDirectory` is a Hadoop [Path]({{ hadoop.api }}/org/apache/hadoop/fs/Path.html) of **Metadata Directory**.

`metadataDirectory` is a [_spark_metadata](FileStreamSink.md#metadataDir) directory in the given [path](#path).

`metadataDirectory` is used to create a [FileStreamSinkLog](#metadataLog).

## <span id="metadataLog"> FileStreamSinkLog

```scala
metadataLog: FileStreamSinkLog
```

`metadataLog` is a [FileStreamSinkLog](FileStreamSinkLog.md) with the [Metadata Directory](#metadataDirectory).

`metadataLog` is used for [metadata log files](#allFilesFromLog).

## <span id="allFilesFromLog"> Metadata Log Files

```scala
allFilesFromLog: Array[FileStatus]
```

`allFilesFromLog` requests the [FileStreamSinkLog](#metadataLog) for [all files](CompactibleFileStreamLog.md#allFiles) that are in turn requested for their [representation as a Hadoop FileStatus](SinkFileStatus.md#toFileStatus).

`allFilesFromLog` is used for [leafFiles](#leafFiles) and [leafDirToChildrenFiles](#leafDirToChildrenFiles).

## <span id="leafFiles"> Leaf Files

```scala
leafFiles: mutable.LinkedHashMap[Path, FileStatus]
```

`leafFiles`...FIXME

`leafFiles` is part of the `PartitioningAwareFileIndex` abstraction ([Spark SQL]({{ book.spark_sql }}/PartitioningAwareFileIndex/#leafFiles)).

## <span id="leafDirToChildrenFiles"> leafDirToChildrenFiles

```scala
leafDirToChildrenFiles: Map[Path, Array[FileStatus]]
```

`leafDirToChildrenFiles`...FIXME

`leafDirToChildrenFiles` is part of the `PartitioningAwareFileIndex` abstraction ([Spark SQL]({{ book.spark_sql }}/PartitioningAwareFileIndex/#leafDirToChildrenFiles)).

## Logging

Enable `ALL` logging level for `org.apache.spark.sql.execution.streaming.MetadataLogFileIndex` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```text
log4j.logger.org.apache.spark.sql.execution.streaming.MetadataLogFileIndex=ALL
```

Refer to [Logging](../../spark-logging.md).
